# Flightsâ€‘Lakehouse Demo âœˆï¸ğŸ—„ï¸

Minimal, reproducible **streamâ€‘toâ€‘lakehouse** sandbox.  Everything runs in DockerÂ Compose; one clone & one command and youâ€™re live.

| Component                     | Purpose                                                 | Image                                |
| ----------------------------- | ------------------------------------------------------- | ------------------------------------ |
| **KafkaÂ 3.5** + **Zookeeper** | Durable event bus                                       | `bitnami/kafka`                      |
| **ksqlDBÂ 0.29**               | Stream processing / CDC                                 | `confluentinc/ksqldb-server`         |
| **ksqlâ€‘init job**             | Automatically creates streams at startup                | `confluentinc/ksqldb-cli`            |
| **MinIO**                     | S3â€‘compatible object storage                            | `minio/minio`                        |
| **PrometheusÂ /Â Grafana**      | Metrics & dashboards                                    | `prom/prometheus`, `grafana/grafana` |
| **Flightâ€‘producer**           | Publishes sample events (PythonÂ 3.11 + confluentâ€‘kafka) | `producers/Dockerfile`               |

---

## 1Â Â Prerequisites

* DockerÂ DesktopÂ 20+
* DockerÂ ComposeÂ v2 (bundled with Docker)
* (Optional)Â GitHubÂ CLI if youâ€™ll push commits

---

## 2Â Â Project layout

```
flightsâ€‘lakehouseâ€‘demo/
â”œ docker/                 â”€ dockerâ€‘compose.yml
â”œ ksql/
â”‚   â”œ init.sql            â”€ declarative stream definition
â”‚   â”” wait.sh             â”€ waits for ksqlDB â†’ runs init.sql
â”œ producers/
â”‚   â”œ Dockerfile          â”€ builds flightâ€‘producer image
â”‚   â”œ requirements.txt
â”‚   â”” produce_flights.py  â”€ reads data/sample_flights.json
â”œ data/
â”‚   â”” sample_flights.json â”€ 10 mock events (extend as you like)
â”” config/
    â”” prometheus.yml
```

---

## 3Â Â QuickÂ start

```bash
# 1Â Â Clone and enter the repo
 git clone https://github.com/<yourâ€‘user>/flightsâ€‘lakehouseâ€‘demo.git
 cd flightsâ€‘lakehouseâ€‘demo/docker

# 2Â Â Launch the stack (Kafka, ksqlDB, MinIO, â€¦)
 docker compose up -d          # ~40Â s the first time

# 3Â Â Publish the sample events
 docker compose build flight-producer   # first time only
 docker compose run --rm flight-producer
```

### Verify

```bash
docker compose exec ksqldb-cli \
  ksql http://ksqldb-server:8088 \
  -e "SET 'auto.offset.reset'='earliest'; \
      SELECT * FROM flight_events_raw EMIT CHANGES LIMIT 10;"
```

You should see the ten rows **IB200Â â€¦Â IB209** and then *LimitÂ Reached*.

---

## 4Â Â Everyâ€‘day commands

| Purpose                          | Command                                                         |
| -------------------------------- | --------------------------------------------------------------- |
| Stop containers (keep data)      | `docker compose stop`                                           |
| Remove containers (keep volumes) | `docker compose down`                                           |
| Full reset (wipe volumes)        | `docker compose down --volumes --remove-orphans`                |
| Tail logs                        | `docker compose logs -f kafka`                                  |
| Enter ksqlDB CLI                 | `docker compose exec ksqldb-cli ksql http://ksqldb-server:8088` |

---

## 5Â Â Changing / adding events

1. Edit **`data/sample_flights.json`** (array of JSON objects).
2. Republish:

```bash
docker compose run --rm flight-producer
```

---

## 6Â Â How the ksqlDB stream is created

`ksql/wait.sh` waits until `http://ksqldb-server:8088/info` responds, then pipes
`ksql/init.sql` into the CLI. If the SQL fails the initâ€‘container exits nonâ€‘zero
and *docker compose ps* shows it immediately.

---

## 7Â Â Troubleshooting

| Symptom                                                                  | How to fix                                                                                                                                                                                                                 |
| ------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `FLIGHT_EVENTS_RAW does not exist`                                       | `docker compose logs ksql-init` â†’ check for SQL error or missing execute bit on **wait.sh**.                                                                                                                               |
| Producer error *Failed to resolveÂ 'kafka:9092'* (running outside Docker) | Use default `localhost:9092` (already in script).                                                                                                                                                                          |
| ARMÂ Mac *exec format error*                                              | `platform: linux/amd64` pinned for ksqlDB images.                                                                                                                                                                          |
| Athena error *Iceberg table without metadata location*                   | Glue entry exists but no Iceberg snapshot yet.<br>â€¢ **OptionÂ A**: run Spark job (next section) â€“ it writes first snapshot.<br>â€¢ **OptionÂ B**: create a dummy table via Athena CTAS (`CREATE TABLE â€¦ AS SELECT 1 LIMIT 0`). |

---

## 8Â Â Deploy to AWS (optional)

### 8.1Â Â Extra prerequisites

| Tool       | MinÂ version | Check                         |
| ---------- | ----------- | ----------------------------- |
| Node.js    | 18          | `node -v`                     |
| npm        | Â 9          | `npm -v`                      |
| AWSÂ CLI    | Â 2          | `aws sts get-caller-identity` |
| AWSÂ CDK v2 | 2.130+      | `cdk --version`               |

### 8.2Â Â Bootstrap & deploy

```bash
cd infra
npm i               # installs CDK libraries
cdk bootstrap aws://<account-id>/<region>   # once
npm run build       # compile TypeScript
cdk deploy          # creates bucket + Glue catalog + Iceberg table
```

Verify in Athena:

1. Set workgroup result location to `s3://flights-raw-<account>/athena-results/`
2. Run `SELECT * FROM flights_demo.flight_legs LIMIT 10;`
   Expect the metadataâ€‘location error until the first snapshot is written.

Destroy:

```bash
cdk destroy
```

---

## 9Â Â Next steps

* **Spark Structured Streaming** â€“ consume `flight-events` and write the first Iceberg snapshot.
* **Dagster + dbt** â€“ build and test analytics layer.

---

## 10Â Â License

MITÂ â€“ free to use, no warranty.
